{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653fe6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion de librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, Normalizer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#ajustes generales\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e3f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones finales (31929, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nametype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recclass",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mass",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "reclat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "reclong",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GeoLocation",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "02cb93a4-c0fb-424e-96d8-2394576b303a",
       "rows": [
        [
         "0",
         "Aachen",
         "1",
         "Valid",
         "L5",
         "21.0",
         "Fell",
         "1880.0",
         "50.775",
         "6.08333",
         "(50.775000, 6.083330)"
        ],
        [
         "1",
         "Aarhus",
         "2",
         "Valid",
         "H6",
         "720.0",
         "Fell",
         "1951.0",
         "56.18333",
         "10.23333",
         "(56.183330, 10.233330)"
        ],
        [
         "2",
         "Abee",
         "6",
         "Valid",
         "EH4",
         "107000.0",
         "Fell",
         "1952.0",
         "54.21667",
         "-113.0",
         "(54.216670, -113.000000)"
        ],
        [
         "3",
         "Acapulco",
         "10",
         "Valid",
         "Acapulcoite",
         "1914.0",
         "Fell",
         "1976.0",
         "16.88333",
         "-99.9",
         "(16.883330, -99.900000)"
        ],
        [
         "4",
         "Achiras",
         "370",
         "Valid",
         "L6",
         "780.0",
         "Fell",
         "1902.0",
         "-33.16667",
         "-64.95",
         "(-33.166670, -64.950000)"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>GeoLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>(50.775000, 6.083330)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>(56.183330, 10.233330)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abee</td>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>(54.216670, -113.000000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>(16.883330, -99.900000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achiras</td>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>(-33.166670, -64.950000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   id nametype     recclass      mass  fall    year    reclat  \\\n",
       "0    Aachen    1    Valid           L5      21.0  Fell  1880.0  50.77500   \n",
       "1    Aarhus    2    Valid           H6     720.0  Fell  1951.0  56.18333   \n",
       "2      Abee    6    Valid          EH4  107000.0  Fell  1952.0  54.21667   \n",
       "3  Acapulco   10    Valid  Acapulcoite    1914.0  Fell  1976.0  16.88333   \n",
       "4   Achiras  370    Valid           L6     780.0  Fell  1902.0 -33.16667   \n",
       "\n",
       "     reclong               GeoLocation  \n",
       "0    6.08333     (50.775000, 6.083330)  \n",
       "1   10.23333    (56.183330, 10.233330)  \n",
       "2 -113.00000  (54.216670, -113.000000)  \n",
       "3  -99.90000   (16.883330, -99.900000)  \n",
       "4  -64.95000  (-33.166670, -64.950000)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtrado de datos\n",
    "\n",
    "#Lectura del dataset ya descargador y descomprimido\n",
    "df = pd.read_csv('./Datasets/meteorite-landings.csv')\n",
    "\n",
    "#Filtrar años validos (860 dC - 2016 dC)\n",
    "df = df[(df['year'] >= 860) & (df['year'] <= 2016)]\n",
    "\n",
    "#Filtrar coordenadas validas\n",
    "df = df[(df['reclong'].between(-180, 180)) & ((df['reclat'] != 0) | (df['reclong'] != 0))]\n",
    "\n",
    "#Eliminar filas con datos nulos en las columnas de interes y reseterar indices\n",
    "df = df.dropna(subset=['year', 'reclat', 'reclong', 'mass', 'recclass'])  \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Mostrar resultados\n",
    "print(f'Dimensiones finales {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b129f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristicas transformadas: (31929, 8), Objetivos: (31929,)\n"
     ]
    }
   ],
   "source": [
    "#Preparacion de datos, para el modelo de clasificación\n",
    "\n",
    "#Seleccionar caracteristicas y objetivo (útiles para el modelo)\n",
    "features = df[['nametype', 'fall', 'mass', 'reclat', 'reclong', 'year']]\n",
    "targets = df['recclass']\n",
    "\n",
    "#type a one-hot, mass a min-max scaling, fall a one-hot, year a estadarizacion, reclat y reclonng normalizacion\n",
    "cathegorical_features = ['nametype', 'fall']\n",
    "numerical_features = ['mass', 'year']\n",
    "coord_features = ['reclat', 'reclong']\n",
    "\n",
    "#Crear el transformador de columnas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), cathegorical_features),\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('coord', Normalizer(), coord_features)\n",
    "    ])\n",
    "#codificar etiquetas de salida\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Aplicar las transformaciones a las caracteristicas y las etiquetas\n",
    "X = preprocessor.fit_transform(features)\n",
    "y = label_encoder.fit_transform(targets)\n",
    "print(f'Caracteristicas transformadas: {X.shape}, Objetivos: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52311ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (19157, 8), Validation set: (6386, 8), Test set: (6386, 8)\n"
     ]
    }
   ],
   "source": [
    "#Dividir los datos en datos de entrenamiento, validacion y testeo\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "print(f'Train set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d044c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de los datasets y dataloaders de pytorch\n",
    "class MeteoriteDatset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "train_dataset = MeteoriteDatset(X_train, y_train)\n",
    "val_dataset = MeteoriteDatset(X_val, y_val)\n",
    "test_dataset = MeteoriteDatset(X_test, y_test)\n",
    "\n",
    "#Creacion de los dataloaders\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34dbc212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeteiriteModule(\n",
       "  (l1): Linear(in_features=8, out_features=128, bias=True)\n",
       "  (a1): ReLU()\n",
       "  (l2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (a2): ReLU()\n",
       "  (l3): Linear(in_features=64, out_features=392, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creación de un modelo de red neuronal\n",
    "class MeteiriteModule(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, 128)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(64, output_dim)\n",
    "\n",
    "        self.modules_list = [self.l1, self.a1, self.l2, self.a2, self.l3]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for mod in self.modules_list:\n",
    "            x = mod(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            preds = torch.argmax(logits, dim=1) #no es necesario softmax\n",
    "        return preds\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(set(y)) #numero de clases únicas\n",
    "\n",
    "model = MeteiriteModule(input_dim, output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf775422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir optimizador y funcion de perdida\n",
    "loss_fn = nn.CrossEntropyLoss() #aplica log_softmax y nll_loss\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d8dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 | Train Loss: 2.7242, Train Acc: 0.2286 | Val Loss: 2.8683, Val Acc: 0.2424\n",
      "Epoch 20/200 | Train Loss: 2.6806, Train Acc: 0.2365 | Val Loss: 2.8884, Val Acc: 0.2418\n",
      "Epoch 30/200 | Train Loss: 2.6420, Train Acc: 0.2433 | Val Loss: 2.9378, Val Acc: 0.2513\n",
      "Epoch 40/200 | Train Loss: 2.5984, Train Acc: 0.2674 | Val Loss: 2.9356, Val Acc: 0.2197\n",
      "Epoch 50/200 | Train Loss: 2.5602, Train Acc: 0.2879 | Val Loss: 2.9435, Val Acc: 0.2891\n",
      "Epoch 60/200 | Train Loss: 2.5325, Train Acc: 0.2905 | Val Loss: 2.9532, Val Acc: 0.2510\n",
      "Epoch 70/200 | Train Loss: 2.5118, Train Acc: 0.2959 | Val Loss: 2.9879, Val Acc: 0.2919\n",
      "Epoch 80/200 | Train Loss: 2.4979, Train Acc: 0.2955 | Val Loss: 2.9666, Val Acc: 0.2922\n",
      "Epoch 90/200 | Train Loss: 2.4951, Train Acc: 0.2961 | Val Loss: 3.0130, Val Acc: 0.2933\n",
      "Epoch 100/200 | Train Loss: 2.4734, Train Acc: 0.3044 | Val Loss: 3.0135, Val Acc: 0.2953\n",
      "Epoch 110/200 | Train Loss: 2.4674, Train Acc: 0.3058 | Val Loss: 3.0390, Val Acc: 0.3019\n",
      "Epoch 120/200 | Train Loss: 2.4625, Train Acc: 0.3059 | Val Loss: 3.0578, Val Acc: 0.3011\n",
      "Epoch 130/200 | Train Loss: 2.4566, Train Acc: 0.3089 | Val Loss: 3.0895, Val Acc: 0.3022\n",
      "Epoch 140/200 | Train Loss: 2.4539, Train Acc: 0.3075 | Val Loss: 3.1047, Val Acc: 0.2952\n",
      "Epoch 150/200 | Train Loss: 2.4444, Train Acc: 0.3115 | Val Loss: 3.1318, Val Acc: 0.3035\n",
      "Epoch 160/200 | Train Loss: 2.4432, Train Acc: 0.3101 | Val Loss: 3.1451, Val Acc: 0.3049\n",
      "Epoch 170/200 | Train Loss: 2.4374, Train Acc: 0.3125 | Val Loss: 3.2261, Val Acc: 0.2731\n",
      "Epoch 180/200 | Train Loss: 2.4344, Train Acc: 0.3134 | Val Loss: 3.1983, Val Acc: 0.3146\n",
      "Epoch 190/200 | Train Loss: 2.4321, Train Acc: 0.3102 | Val Loss: 3.2055, Val Acc: 0.3101\n",
      "Epoch 200/200 | Train Loss: 2.4270, Train Acc: 0.3122 | Val Loss: 3.2538, Val Acc: 0.2997\n"
     ]
    }
   ],
   "source": [
    "#Funcion de entrenamiento y validacion\n",
    "model.to(DEVICE)\n",
    "def train_model(model, train_dl, val_dl, loss_fn, optimizer, epochs=120):\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- Entrenamiento -----\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad() #limpiar gradientes\n",
    "            logits = model(x_batch) #forward pass\n",
    "            loss = loss_fn(logits, y_batch) #calcular perdida\n",
    "            loss.backward() #backward pass\n",
    "            optimizer.step() #actualizar pesos\n",
    "\n",
    "            #Acumular perdida y aciertos\n",
    "            epoch_loss += loss.item() * x_batch.size(0)\n",
    "            correct += (logits.argmax(1) == y_batch).sum().item() #aciertos\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        train_losses.append(epoch_loss / total)\n",
    "        train_accuracies.append(correct / total)\n",
    "\n",
    "        # ----- Validación -----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad(): #no calcular gradientes\n",
    "            for x_batch, y_batch in val_dl:\n",
    "                x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "                logits = model(x_batch)\n",
    "                loss = loss_fn(logits, y_batch)\n",
    "\n",
    "                val_loss += loss.item() * x_batch.size(0)\n",
    "                val_correct += (logits.argmax(1) == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "\n",
    "        val_losses.append(val_loss / val_total)\n",
    "        val_accuracies.append(val_correct / val_total)\n",
    "\n",
    "        # ----- Print cada 20 epochs -----\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f} | \"\n",
    "                  f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "\n",
    "#Entrenar el modelo\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train_model(\n",
    "    model, train_dl, val_dl, loss_fn, optimizer, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e078dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.2964\n"
     ]
    }
   ],
   "source": [
    "#Testear el modelo\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_dl:\n",
    "        x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        logits = model(x_batch)\n",
    "        test_correct += (logits.argmax(1) == y_batch).sum().item()\n",
    "        test_total += y_batch.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
